{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jzech\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jzech\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Short stories have deep roots and the power of short fiction has been recognised in modern society for hundreds of years.', 'The short form is, conceivably, more natural to us than longer forms.', 'We are drawn to short stories as the well-told story, and as William Boyd, the award-winning British author and short story writer has said:']\n",
      "['Short', 'stories', 'have', 'deep', 'roots', 'and', 'the', 'power', 'of', 'short', 'fiction', 'has', 'been', 'recognised', 'in', 'modern', 'society', 'for', 'hundreds', 'of', 'years', '.', 'The', 'short', 'form', 'is', ',', 'conceivably', ',', 'more', 'natural', 'to', 'us', 'than', 'longer', 'forms', '.', 'We', 'are', 'drawn', 'to', 'short', 'stories', 'as', 'the', 'well-told', 'story', ',', 'and', 'as', 'William', 'Boyd', ',', 'the', 'award-winning', 'British', 'author', 'and', 'short', 'story', 'writer', 'has', 'said', ':']\n",
      "And the summary is....\n",
      " We are drawn to short stories as the well-told story, and as William Boyd, the award-winning British author and short story writer has said:\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "#https://www.msn.com/en-us/news/world/putin-russia-knows-mueller-probe-gave-birth-to-a-mouse/ar-BBVLtjG?ocid=spartanntp\n",
    "#https://www.msn.com/en-us/health/health-news/a-new-cancer-vaccine-uses-the-immune-system-to-take-out-tumors/ar-BBVLDdK?ocid=spartanntp\n",
    "r = requests.get('https://www.msn.com/en-us/news/world/putin-russia-knows-mueller-probe-gave-birth-to-a-mouse/ar-BBVLtjG?ocid=spartanntp')\n",
    "\n",
    "text = 'Short stories have deep roots and the power of short fiction has been recognised in modern society for hundreds of years. The short form is, conceivably, more natural to us than longer forms. We are drawn to short stories as the well-told story, and as William Boyd, the award-winning British author and short story writer has said:'\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "#rint(stopWords)\n",
    "#print(r.text)\n",
    "#print(soup.findAll('p'))\n",
    "#print(soup.prettify())\n",
    "paras = soup.findAll('p', string=True)\n",
    "\n",
    "#print(paras)\n",
    "paragraphs = []\n",
    "for para in paras:\n",
    "    paragraphs.append(para.text)\n",
    "\n",
    "#print(paragraphs)\n",
    "#getting a list of sentences from an article\n",
    "exSentences = sent_tokenize(text)\n",
    "print(exSentences)\n",
    "sentences = []\n",
    "sentences = [sent_tokenize(sent) for sent in paragraphs]\n",
    "#print(sentences)\n",
    "#for i in range (len(paragraphs)):\n",
    "#    sentences.append(sent_tokenize(paragraphs[i]))\n",
    "#print(sentences)\n",
    "with open('sentences.pkl', 'wb') as f:\n",
    "    pickle.dump(sentences, f)\n",
    "with open('sentences.pkl', 'rb') as f:\n",
    "    pickled_sents = pickle.load(f)\n",
    "#print(pickled_sents)\n",
    "\n",
    "#tokens = [word_tokenize(s) for s in sentences]\n",
    "#print(tokens)\n",
    "#getting a list of words\n",
    "#words = list()\n",
    "#for sent in sentences:\n",
    "#    words.extend(map(lambda x: x.lower(), word_tokenize(sent)))\n",
    "#print(words)\n",
    "\n",
    "words = word_tokenize(text)\n",
    "print(words)\n",
    "\n",
    "#frequency table\n",
    "freqTable = dict()\n",
    "for word in words:\n",
    "    word = word.lower()\n",
    "    if word in stopWords:\n",
    "        continue\n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] = 1\n",
    "#sentence score        \n",
    "sentenceValue = dict()\n",
    "\n",
    "for sentence in exSentences:\n",
    "    for word, freq in freqTable.items():\n",
    "        if word in sentence.lower():\n",
    "            if sentence in sentenceValue:\n",
    "                sentenceValue[sentence] += freq\n",
    "            else:\n",
    "                sentenceValue[sentence] = freq\n",
    "sumValues = 0\n",
    "for sentence in sentenceValue:\n",
    "    sumValues += sentenceValue[sentence]\n",
    "\n",
    "average = int(sumValues/ len(sentenceValue))\n",
    "\n",
    "summary = ''\n",
    "for sentence in exSentences:\n",
    "    if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
    "        summary += ' ' + sentence\n",
    "print('And the summary is....')\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
